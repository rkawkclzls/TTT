{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/fhOEWfwkNRzTlxzWmgeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkawkclzls/TTT/blob/master/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7_IJMhiBovy"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install transformers datasets\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from datasets import load_dataset\n",
        "\n",
        "# GPU 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# AG News 데이터셋 로드\n",
        "ds = load_dataset(\"fancyzhx/ag_news\")\n",
        "\n",
        "# GPT 토크나이저 로드 및 패딩 토큰 추가\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('openai-gpt')\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "\n",
        "# 데이터 필터링 함수\n",
        "def filter_dataset(example):\n",
        "    return example['text'] and isinstance(example['text'], str)\n",
        "\n",
        "# collate_fn 정의: 배치 데이터 처리\n",
        "def collate_fn(batch):\n",
        "    texts, labels = [], []\n",
        "    for row in batch:\n",
        "        if row['text'] and isinstance(row['text'], str):\n",
        "            labels.append(row['label'])\n",
        "            texts.append(row['text'])\n",
        "\n",
        "    if not texts:  # 모든 텍스트가 유효하지 않은 경우\n",
        "        return None, None\n",
        "\n",
        "    encoded = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    return encoded, torch.LongTensor(labels)\n",
        "\n",
        "# 필터링된 데이터셋 생성\n",
        "filtered_train = ds['train'].filter(filter_dataset)\n",
        "filtered_test = ds['test'].filter(filter_dataset)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_loader = DataLoader(filtered_train, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(filtered_test, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# TextClassifier 모델 정의\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = GPT2Model.from_pretrained('openai-gpt')\n",
        "        self.classifier = nn.Linear(768, 4)  # AG News has 4 classes\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # 마지막 토큰의 hidden state를 사용\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        pooled_output = last_hidden_state[:, -1, :]\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "# 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = TextClassifier().to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "    for batch in dataloader:\n",
        "        if batch[0] is None:  # None 값 건너뛰기\n",
        "            continue\n",
        "        inputs, labels = batch\n",
        "        input_ids = inputs['input_ids'].to(device)\n",
        "        attention_mask = inputs['attention_mask'].to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_batches += 1\n",
        "    return total_loss / total_batches if total_batches > 0 else 0\n",
        "\n",
        "# 평가 함수 정의\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            if batch[0] is None:  # None 값 건너뛰기\n",
        "                continue\n",
        "            inputs, labels = batch\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "            attention_mask = inputs['attention_mask'].to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "# 학습 루프\n",
        "n_epochs = 3\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "# 최종 평가\n",
        "test_acc = evaluate(model, test_loader)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
      ]
    }
  ]
}